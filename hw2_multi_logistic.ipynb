{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reading the data you can use either numpy or pandas and accordingly handle your processing. An example could be\n",
    "# my_data = np.genfromtxt('SPAM-HW1.csv', delimiter=',')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    sig_x = 1.0/(1 + np.exp(-x))\n",
    "    return sig_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_logistic_train(X_train, y_train, itermax=1000, eta = 1):\n",
    "    dataMatrix = np.mat(X_train)\n",
    "    labelMat = y_train\n",
    "    m, n = dataMatrix.shape\n",
    "    theta = np.ones((n, 1))\n",
    "    for i in range(itermax):\n",
    "        h = sigmoid(dataMatrix.dot(theta))\n",
    "        error = h - labelMat\n",
    "        theta = theta - eta * (dataMatrix.T * error)\n",
    "    return np.asarray(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_logistic_train(X_train, y_train, itermax=1000, eta = 0.001, mini_len = 200):\n",
    "    \"\"\"\n",
    "    This function should implement fitting or training your model in question. \n",
    "    \"\"\"\n",
    "    dataMatrix = np.mat(X_train)\n",
    "    labelMat = y_train\n",
    "    m, n = dataMatrix.shape\n",
    "    theta = np.ones(n)\n",
    "    for i in range(itermax):\n",
    "        randIndex = int(np.random.uniform(0, m))\n",
    "        for k in range(mini_len):\n",
    "            h = sigmoid(np.dot(mnist_train_X[randIndex],theta))\n",
    "            error = h -mnist_train_y[randIndex]\n",
    "            theta = theta - eta * (error * mnist_train_X[randIndex])\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_logistic_train(X_train, y_train, itermax=100, eta = 1, mini_len = 500, class_num = 10):\n",
    "    \"\"\"\n",
    "    This function should implement fitting or training your model in question. \n",
    "    \"\"\"\n",
    "    m, n = X_train.shape\n",
    "    mnist_train_y_class = []\n",
    "    for i in range(m):\n",
    "        mnist_train_y_class.append([0]*class_num)\n",
    "        mnist_train_y_class[i][y_train[i]] = 1\n",
    "    mnist_train_y_mat = np.mat(mnist_train_y_class)\n",
    "    theta = []\n",
    "    for i in range(class_num):\n",
    "        theta_tmp = single_logistic_train(X_train, mnist_train_y_mat[:,i], itermax, eta).reshape((n,1))\n",
    "        theta.append(theta_tmp[:,0])\n",
    "    return np.mat(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_logistic_predict(X_valid,theta):\n",
    "    \"\"\"\n",
    "    Here, using the trained model, implement how to predict when you just have feature vector. \n",
    "    \"\"\"\n",
    "    h=np.dot(mnist_train_X, theta.T)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-176df8144337>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mmnist_test_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mmnist_test_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist_train_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmulti_logistic_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist_train_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmnist_train_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmulti_logistic_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist_test_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mh_argmax\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-60-c49be9821717>\u001b[0m in \u001b[0;36mmulti_logistic_train\u001b[1;34m(X_train, y_train, itermax, eta, mini_len, class_num)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mtheta_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msingle_logistic_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmnist_train_y_mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitermax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mtheta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta_tmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-f30c7ee49d5b>\u001b[0m in \u001b[0;36msingle_logistic_train\u001b[1;34m(X_train, y_train, itermax, eta)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitermax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataMatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlabelMat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0meta\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdataMatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\matrixlib\\defmatrix.py\u001b[0m in \u001b[0;36m__array_finalize__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__array_finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Main - Here goes the overall logic.\n",
    "\"\"\"\n",
    "# cross-validation to get train and validation data\n",
    "# We will use cross validation for training and validation. In this assignment, we will not use test split separately.\n",
    "#  Let us say we want k-fold with k=5 - shuffle the data and partition into k-equal partitions\n",
    "#  Save paritions into dictionaries\n",
    "np.random.seed(5525)\n",
    "mnist_train = pd.read_csv('mnist_train.csv',delimiter = ',',header = None)\n",
    "mnist_test = pd.read_csv('mnist_test.csv',delimiter = ',',header = None)\n",
    "mnist_train_X = mnist_train.iloc[:,1:]\n",
    "mnist_train_X = np.array(mnist_train_X)\n",
    "mnist_train_y = mnist_train.iloc[:,0]\n",
    "mnist_train_y = np.array(mnist_train_y)\n",
    "mnist_test_X = mnist_test.iloc[:,1:]\n",
    "mnist_test_X = np.array(mnist_train_X)\n",
    "mnist_test_y = mnist_test.iloc[:,0]\n",
    "mnist_test_y = np.array(mnist_train_y)\n",
    "theta = multi_logistic_train(mnist_train_X, mnist_train_y)\n",
    "h=multi_logistic_predict(mnist_test_X,theta)\n",
    "h_argmax= np.argmax(h, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix is:\n",
      "[[1.74098666e+11 1.81634606e+11 1.88092111e+11 ... 1.58569834e+11\n",
      "  1.78473677e+11 1.81725845e+11]\n",
      " [1.73671600e+11 1.75035434e+11 1.75650691e+11 ... 1.55947964e+11\n",
      "  1.72525012e+11 1.66237580e+11]\n",
      " [8.49639356e+10 9.31362914e+10 9.48744600e+10 ... 7.30353798e+10\n",
      "  8.80912178e+10 8.61715926e+10]\n",
      " ...\n",
      " [1.33391034e+11 1.48070945e+11 1.54977312e+11 ... 1.34460670e+11\n",
      "  1.54254362e+11 1.50280778e+11]\n",
      " [1.19030089e+11 1.19155127e+11 1.16536342e+11 ... 1.05606833e+11\n",
      "  1.23470367e+11 1.07750820e+11]\n",
      " [1.28511404e+11 1.29092378e+11 1.31716189e+11 ... 1.27381802e+11\n",
      "  1.31146868e+11 1.24822560e+11]]\n"
     ]
    }
   ],
   "source": [
    "print(\"The confusion matrix is:\")\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:\n",
      "0.1031\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy is:\")\n",
    "print(sum(np.array(h_argmax).ravel() == mnist_train_y)/len(mnist_train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
